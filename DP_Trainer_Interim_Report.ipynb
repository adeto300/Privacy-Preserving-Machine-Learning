{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dd6bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c686be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Resizing, Rescaling\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.layers import LayerNormalization\n",
    "from tensorflow_privacy.privacy.optimizers.dp_optimizer_keras import DPKerasSGDOptimizer\n",
    "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow_addons.layers import GroupNormalization, InstanceNormalization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3fc2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "#pip install clyent==1.2.1 pyyaml==6.0.1\n",
    "\n",
    "# %%\n",
    "#!pip show tensorflow-addons\n",
    "#!pip show tensorflow\n",
    "#!pip install tensorflow-addons==0.22.0\n",
    "#!pip install tensorflow==2.15.0\n",
    "\n",
    "\n",
    "# %%\n",
    "#!pip list\n",
    "\n",
    "# %%\n",
    "#pip install --upgrade pip\n",
    "\n",
    "# %%\n",
    "#pip install tensorflow-privacy==0.5.0\n",
    "\n",
    "# %%\n",
    "#pip install python3.11\n",
    "\n",
    "# %%\n",
    "#!pip install cmake\n",
    "\n",
    "# %%\n",
    "#pip install matplotlib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc71e35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Load CIFAR10 dataset: 60k 32x32 RGB images (50k training set + 10k test set)\n",
    "(train_data, train_labels), (test_data, test_labels) = cifar10.load_data()\n",
    "\n",
    "# %%\n",
    "# Normalize pixel values\n",
    "#train_data, test_data = train_data / 255.0, test_data / 255.0\n",
    "\n",
    "# %%\n",
    "# Normalize the pixel values of the train and test data\n",
    "train_data = train_data.astype('float32') / 255.0\n",
    "test_data = test_data.astype('float32') / 255.0\n",
    "\n",
    "# %%\n",
    "# ResNet50 expects input size of (224, 224, 3)\n",
    "resize_and_rescale = tf.keras.Sequential([\n",
    "    Resizing(224, 224),\n",
    "        Rescaling(1./255)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3472b568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "#10 lAYERS\n",
    "\n",
    "model_cnn = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),  # Layer 1: Conv2D\n",
    "    LayerNormalization(),  # Layer 2: LayerNormalization\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),  # Layer 3: MaxPooling2D\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),  # Layer 4: Conv2D\n",
    "    tf.keras.layers.Dropout(0.25),  # Layer 5: Dropout\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),  # Layer 6: Conv2D\n",
    "    GroupNormalization(),  # Layer 7: GroupNormalization\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),  # Layer 8: MaxPooling2D\n",
    "    tf.keras.layers.Flatten(),  # Layer 9: Flatten\n",
    "    tf.keras.layers.Dense(128, activation='relu'),  # Layer 10: Dense\n",
    "    tf.keras.layers.Dense(10, activation='softmax')  # Output layer: Dense with softmax for multi-class classification\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7438fcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Define the input tensor\n",
    "input_tensor = Input(shape=(32, 32, 3))\n",
    "\n",
    "# Resizing and Rescaling layers\n",
    "# Here assuming that Resizing is to a larger dimension such as (224, 224)\n",
    "# And Rescaling is to ensure pixel values are between 0 and 1\n",
    "x = Resizing(224, 224, interpolation='bilinear')(input_tensor)\n",
    "x = Rescaling(1./255)(x)\n",
    "\n",
    "# Instantiate the ResNet50V2 model\n",
    "# Note: weights=None implies random initialization since CIFAR-10 is a different domain from ImageNet\n",
    "# include_top=False removes the fully connected layers at the top of the network, allowing for custom classifier layers\n",
    "base_model = ResNet50V2(weights=None, include_top=False, input_tensor=x)\n",
    "\n",
    "# Ensure that the base model's layers are set to be non-trainable\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom layers on top of the base model\n",
    "x = Flatten()(base_model.output)\n",
    "output_layer = Dense(10, activation='softmax')(x)  # CIFAR10 has 10 classes\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eee6817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final model\n",
    "model = Model(inputs=input_tensor, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316f59bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# resnetv2 Model summary to verify the number of layers\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c995ed77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# cnn Model summary to verify the number of layers\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f841e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "#ε and δ: Set your ε (epsilon) and δ (delta) values.\n",
    "epsilon = 3.0\n",
    "delta = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7bb57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your dataset size\n",
    "num_examples = len(train_data)  \n",
    "\n",
    "# %%\n",
    "\n",
    "# Define parameters for DP-SGD FOR RESNET50V2\n",
    "noise_multiplier = 0.937  # Adjusted for tighter privacy guarantee\n",
    "l2_norm_clip = 1.5\n",
    "batch_size = 30\n",
    "learning_rate = 0.001\n",
    "epochs = 200 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c2afc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Define parameters for DP-SGD FOR CNN\n",
    "noise_multiplier_cnn = 3.03  # Adjusted for tighter privacy guarantee\n",
    "l2_norm_clip_cnn = 1.5\n",
    "batch_size_cnn = 300 \n",
    "learning_rate_cnn = 0.001\n",
    "epochs_cnn = 500 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3056ab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Compute the privacy budget expended during ResNetV2 training\n",
    "epsilon= compute_dp_sgd_privacy.compute_dp_sgd_privacy(\n",
    "    len(train_data), \n",
    "    batch_size, \n",
    "    noise_multiplier,\n",
    "    epochs, \n",
    "    delta=delta)[0]\n",
    "\n",
    "# %%\n",
    "print(f\"Trained with DP-SGD with ε = {epsilon:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3dc34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the privacy budget expended during CNN training\n",
    "\n",
    "epsilon= compute_dp_sgd_privacy.compute_dp_sgd_privacy(\n",
    "    len(train_data), \n",
    "    batch_size = batch_size_cnn, \n",
    "    noise_multiplier = noise_multiplier_cnn,\n",
    "    epochs= epochs_cnn, \n",
    "    delta=delta)[0]\n",
    "\n",
    "\n",
    "# %%\n",
    "print(f\"Trained with DP-SGD with ε = {epsilon:.2f}\")\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca40767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DP-SGD optimizer model ResNetV2\n",
    "optimizers = DPKerasSGDOptimizer(\n",
    "    l2_norm_clip=l2_norm_clip,\n",
    "    noise_multiplier=noise_multiplier,\n",
    "    num_microbatches=batch_size,\n",
    "    learning_rate=learning_rate\n",
    ")\n",
    "\n",
    "#l2_norm_clip: This parameter sets a threshold for clipping the L2 norm of gradients, which prevents any single \n",
    "#data point from having a disproportionate impact on the computation of gradients, thereby safeguarding individual \n",
    "#data point privacy.\n",
    "\n",
    "#noise_multiplier: This determines the amount of random noise added to the gradients during training. The noise helps \n",
    "#mask the contribution of individual data points, which is central to achieving differential privacy.\n",
    "\n",
    "#num_microbatches: This parameter controls the subdivision of a batch into smaller units, or microbatches. Processing \n",
    "#these microbatches separately and then aggregating their gradients ensures that the influence of any single data point \n",
    "#is limited.\n",
    "\n",
    "#learning_rate: While not directly related to privacy, the learning rate can impact the convergence of the training \n",
    "#process, especially when combined with the other DP parameters.\n",
    "\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054f7f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create DP-SGD optimizer model cnn\n",
    "optimizers_cnn = DPKerasSGDOptimizer(\n",
    "    l2_norm_clip=l2_norm_clip_cnn,\n",
    "    noise_multiplier=noise_multiplier_cnn,\n",
    "    num_microbatches=batch_size_cnn,\n",
    "    learning_rate=learning_rate_cnn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1bd489",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "#loss forresnet \n",
    "#loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.losses.Reduction.NONE)\n",
    "\n",
    "#since our model is already normalized with softmax we set the logits to false\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "# %%\n",
    "#loss for cnn\n",
    "#loss_cnn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.losses.Reduction.NONE)\n",
    "\n",
    "#since our model is already normalized with softmax we set the logits to false\n",
    "loss_cnn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cf2cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Define RMSE as a custom metric\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf8b4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "#define model parameters for cnn\n",
    "model_cnn.compile(optimizer=optimizers_cnn, loss=loss_cnn, metrics=['accuracy', rmse])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aa2c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "#define model parameters for resnetv2\n",
    "model.compile(optimizer=optimizers, loss=loss, metrics=['accuracy', rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ceaed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# cnn Train the model on 50k training images and validate on 10k test images\n",
    "# Train the model with differential privacy\n",
    "history_cnn = model_cnn.fit(\n",
    "    train_data, \n",
    "    train_labels, \n",
    "    epochs=epochs_cnn, \n",
    "    batch_size=batch_size_cnn, \n",
    "    validation_data=(test_data, test_labels)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975320c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# resnetv2 Train the model on 50k training images and validate on 10k test images\n",
    "# Train the model with differential privacy\n",
    "history = model.fit(\n",
    "    train_data, \n",
    "    train_labels, \n",
    "    epochs=epochs, \n",
    "    batch_size=batch_size, \n",
    "    validation_data=(test_data, test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8001364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Resnetv2 After training, multiply accuracy by 100 to convert to percentage\n",
    "final_accuracy = history.history['accuracy'][-1] * 100\n",
    "final_val_accuracy = history.history['val_accuracy'][-1] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55360262",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# cnn After training, multiply accuracy by 100 to convert to percentage\n",
    "final_accuracy_cnn = history_cnn.history['accuracy'][-1] * 100\n",
    "final_val_accuracy_cnn = history_cnn.history['val_accuracy'][-1] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3e2abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "print(f\"Final training accuracy for ResNetV2: {final_accuracy}%\")\n",
    "print(f\"Final validation accuracy for ResNetV2: {final_val_accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea77861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "print(f\"Final training accuracy for cnn: {final_accuracy_cnn}%\")\n",
    "print(f\"Final validation accuracy for cnn: {final_val_accuracy_cnn}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea96d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Assuming you have the history object from model.fit\n",
    "# Example: history = model.fit(train_data, train_labels, epochs=epochs, batch_size=batch_size, validation_data=(test_data, test_labels))\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fefb71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extracting metrics from the history object resnetv2\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "rmse = history.history['rmse']\n",
    "val_rmse = history.history['val_rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182cd676",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Extracting metrics from the history object cnn\n",
    "loss_cnn = history_cnn.history['loss']\n",
    "val_loss_cnn = history_cnn.history['val_loss']\n",
    "accuracy_cnn = history_cnn.history['accuracy']\n",
    "val_accuracy_cnn = history_cnn.history['val_accuracy']\n",
    "rmse_cnn = history_cnn.history['rmse']\n",
    "val_rmse_cnn = history_cnn.history['val_rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df4d59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of epochs\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "epochs_cnn = range(1, len(loss_cnn) + 1)\n",
    "# ... [Your existing code] ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32e895d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs, loss, 'b-', label='ResNetV2 Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r-', label='ResNetV2 Validation Loss')\n",
    "plt.plot(epochs_cnn, loss_cnn, 'b--', label='CNN Training Loss')\n",
    "plt.plot(epochs_cnn, val_loss_cnn, 'r--', label='CNN Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55ceebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotting Accuracy\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs, accuracy, 'g-', label='ResNetV2 Training Accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'k-', label='ResNetV2 Validation Accuracy')\n",
    "plt.plot(epochs_cnn, accuracy_cnn, 'g--', label='CNN Training Accuracy')\n",
    "plt.plot(epochs_cnn, val_accuracy_cnn, 'k--', label='CNN Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342343ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Plotting RMSE\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(epochs, rmse, 'y-', label='ResNetV2 Training RMSE')\n",
    "plt.plot(epochs, val_rmse, 'c-', label='ResNetV2 Validation RMSE')\n",
    "plt.plot(epochs_cnn, rmse_cnn, 'y--', label='CNN Training RMSE')\n",
    "plt.plot(epochs_cnn, val_rmse_cnn, 'c--', label='CNN Validation RMSE')\n",
    "plt.title('Training and Validation RMSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13db14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
